{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-22T06:39:22.577128Z",
     "start_time": "2025-06-22T06:39:22.568178Z"
    }
   },
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T06:39:22.609355Z",
     "start_time": "2025-06-22T06:39:22.600196Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TEXBATSequenceDataset(Dataset):\n",
    "    def __init__(self, data_dir, label_file, window_size=256, pred_len=16, step_size=32):\n",
    "        self.data_dir = data_dir\n",
    "        self.window_size = window_size\n",
    "        self.pred_len = pred_len\n",
    "        self.step_size = step_size\n",
    "\n",
    "        # 读取标签文件：chunk_XXX.npy, label\n",
    "        self.labels = {}\n",
    "        with open(label_file, 'r') as f:\n",
    "            for line in f:\n",
    "                name, label = line.strip().split(',')\n",
    "                self.labels[name.strip()] = int(label.strip())\n",
    "\n",
    "        # 构建所有索引 (chunk_name, 起始位置, 标签)\n",
    "        self.index = []\n",
    "        for filename in sorted(os.listdir(data_dir)):\n",
    "            if filename.endswith('.npy') and filename in self.labels:\n",
    "                full_path = os.path.join(data_dir, filename)\n",
    "                num_points = os.path.getsize(full_path) // 16  # complex128 = 16 bytes\n",
    "                max_start = num_points - (window_size + pred_len)\n",
    "                for start in range(0, max_start, step_size):\n",
    "                    self.index.append((filename, start, self.labels[filename]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.index)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.load_sequence_by_index(self.index[idx])\n",
    "\n",
    "    def load_sequence_by_index(self, index_entry):\n",
    "        chunk_file, start, label = index_entry\n",
    "        path = os.path.join(self.data_dir, chunk_file)\n",
    "        data = np.load(path)\n",
    "        x = data[start : start + self.window_size]\n",
    "        y = data[start + self.window_size : start + self.window_size + self.pred_len]\n",
    "        x_tensor = torch.from_numpy(np.stack([x.real, x.imag], axis=-1)).float()\n",
    "        y_tensor = torch.from_numpy(np.stack([y.real, y.imag], axis=-1)).float()\n",
    "        return x_tensor, y_tensor, torch.tensor(label)\n",
    "\n",
    "    def get_task_data(self, label=None):\n",
    "        return self.index if label is None else [item for item in self.index if item[2] == label]"
   ],
   "id": "28c9088b252848d",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T06:39:22.648511Z",
     "start_time": "2025-06-22T06:39:22.623305Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_dir = \"Dataset/DS7\"\n",
    "label_file = \"Dataset/ds7_labels.txt\"\n",
    "\n",
    "dataset = TEXBATSequenceDataset(\n",
    "    data_dir=data_dir,\n",
    "    label_file=label_file,\n",
    "    window_size=256,\n",
    "    pred_len=16,\n",
    "    step_size=32\n",
    ")\n",
    "\n",
    "# 尝试取一条看看\n",
    "x, y, label = dataset[0]\n",
    "print(\"x shape:\", x.shape)     # [256, 2]\n",
    "print(\"y shape:\", y.shape)     # [16, 2]\n",
    "print(\"label:\", label)         # tensor(0) or tensor(1)\n"
   ],
   "id": "4bbfafa8cc8501bf",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 系统找不到指定的路径。: 'Dataset/DS7'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m data_dir \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset/DS7\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m      2\u001B[0m label_file \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset/ds7_labels.txt\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m----> 4\u001B[0m dataset \u001B[38;5;241m=\u001B[39m TEXBATSequenceDataset(\n\u001B[0;32m      5\u001B[0m     data_dir\u001B[38;5;241m=\u001B[39mdata_dir,\n\u001B[0;32m      6\u001B[0m     label_file\u001B[38;5;241m=\u001B[39mlabel_file,\n\u001B[0;32m      7\u001B[0m     window_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m256\u001B[39m,\n\u001B[0;32m      8\u001B[0m     pred_len\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m16\u001B[39m,\n\u001B[0;32m      9\u001B[0m     step_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m32\u001B[39m\n\u001B[0;32m     10\u001B[0m )\n\u001B[0;32m     12\u001B[0m \u001B[38;5;66;03m# 尝试取一条看看\u001B[39;00m\n\u001B[0;32m     13\u001B[0m x, y, label \u001B[38;5;241m=\u001B[39m dataset[\u001B[38;5;241m0\u001B[39m]\n",
      "Cell \u001B[1;32mIn[8], line 17\u001B[0m, in \u001B[0;36mTEXBATSequenceDataset.__init__\u001B[1;34m(self, data_dir, label_file, window_size, pred_len, step_size)\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;66;03m# 构建所有索引 (chunk_name, 起始位置, 标签)\u001B[39;00m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindex \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m---> 17\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m filename \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28msorted\u001B[39m(os\u001B[38;5;241m.\u001B[39mlistdir(data_dir)):\n\u001B[0;32m     18\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m filename\u001B[38;5;241m.\u001B[39mendswith(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.npy\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m filename \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlabels:\n\u001B[0;32m     19\u001B[0m         full_path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(data_dir, filename)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [WinError 3] 系统找不到指定的路径。: 'Dataset/DS7'"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T06:39:22.648511Z",
     "start_time": "2025-06-15T13:12:03.865771Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LSTMPredictor(nn.Module):\n",
    "    def __init__(self, input_dim=2, hidden_dim=64, num_layers=2, output_len=16):\n",
    "        super(LSTMPredictor, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_len = output_len\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_dim, hidden_size=hidden_dim,\n",
    "                            num_layers=num_layers, batch_first=True)\n",
    "\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 2)  # 预测复数（实部、虚部）\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [batch, seq_len=256, 2]\n",
    "        lstm_out, _ = self.lstm(x)  # 输出维度：[batch, seq_len, hidden]\n",
    "        last_outputs = lstm_out[:, -self.output_len:, :]  # 取最后 N 步\n",
    "        pred = self.linear(last_outputs)  # [batch, pred_len, 2]\n",
    "        return pred\n"
   ],
   "id": "ef255518d4b8d718",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T06:39:22.648511Z",
     "start_time": "2025-06-15T13:17:26.442248Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model = LSTMPredictor().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ],
   "id": "2655126c262a087c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T06:39:22.673306900Z",
     "start_time": "2025-06-15T13:17:49.632076Z"
    }
   },
   "cell_type": "code",
   "source": "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)",
   "id": "d25af1293571d96d",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T06:39:22.673306900Z",
     "start_time": "2025-06-22T06:37:28.367805Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.train()\n",
    "for i, (x, y, label) in enumerate(train_loader):\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    output = model(x)\n",
    "    loss = criterion(output, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(f\"[Batch {i}] Loss: {loss.item():.6f}\")\n",
    "\n",
    "    if i == 30:  # 先跑 30 个 batch 看显存表现\n",
    "        break\n"
   ],
   "id": "76840bbe58804470",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import random\n",
    "\n",
    "def sample_support_query(dataset, support_size=5, query_size=15, label=1):\n",
    "    \"\"\"\n",
    "    从 dataset 中采样 support/query 集（用于 meta-task）\n",
    "    label: 只采该标签的样本（默认=1 表示 spoofed 样本）\n",
    "    \"\"\"\n",
    "    # 获取指定类别下的所有索引\n",
    "    candidates = dataset.get_task_data(label=label)\n",
    "    total_needed = support_size + query_size\n",
    "    assert len(candidates) >= total_needed, f\"可用样本数不足（共 {len(candidates)}）\"\n",
    "\n",
    "    # 随机采样\n",
    "    selected = random.sample(candidates, total_needed)\n",
    "    support_indices = selected[:support_size]\n",
    "    query_indices = selected[support_size:]\n",
    "\n",
    "    # 分别加载 support / query 数据\n",
    "    support_set = [dataset.load_sequence_by_index(idx) for idx in support_indices]\n",
    "    query_set = [dataset.load_sequence_by_index(idx) for idx in query_indices]\n",
    "\n",
    "    return support_set, query_set\n"
   ],
   "id": "d2a530089394f7b3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-15T13:08:01.774558Z",
     "start_time": "2025-06-15T13:07:59.333313Z"
    }
   },
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T13:08:05.892104Z",
     "start_time": "2025-06-15T13:08:05.884824Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TEXBATSequenceDataset(Dataset):\n",
    "    def __init__(self, data_dir, label_file, window_size=256, pred_len=16, step_size=32):\n",
    "        self.data_dir = data_dir\n",
    "        self.window_size = window_size\n",
    "        self.pred_len = pred_len\n",
    "        self.step_size = step_size\n",
    "\n",
    "        # 读取标签文件：chunk_XXX.npy, label\n",
    "        self.labels = {}\n",
    "        with open(label_file, 'r') as f:\n",
    "            for line in f:\n",
    "                name, label = line.strip().split(',')\n",
    "                self.labels[name.strip()] = int(label.strip())\n",
    "\n",
    "        # 构建所有索引 (chunk_name, 起始位置, 标签)\n",
    "        self.index = []\n",
    "        for filename in sorted(os.listdir(data_dir)):\n",
    "            if filename.endswith('.npy') and filename in self.labels:\n",
    "                full_path = os.path.join(data_dir, filename)\n",
    "                num_points = os.path.getsize(full_path) // 16  # complex128 = 16 bytes\n",
    "                max_start = num_points - (window_size + pred_len)\n",
    "                for start in range(0, max_start, step_size):\n",
    "                    self.index.append((filename, start, self.labels[filename]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.index)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        chunk_file, start, label = self.index[idx]\n",
    "        path = os.path.join(self.data_dir, chunk_file)\n",
    "        data = np.load(path)\n",
    "        x = data[start : start + self.window_size]\n",
    "        y = data[start + self.window_size : start + self.window_size + self.pred_len]\n",
    "        x_tensor = torch.from_numpy(np.stack([x.real, x.imag], axis=-1)).float()\n",
    "        y_tensor = torch.from_numpy(np.stack([y.real, y.imag], axis=-1)).float()\n",
    "        return x_tensor, y_tensor, torch.tensor(label)\n"
   ],
   "id": "28c9088b252848d",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T13:09:51.447793Z",
     "start_time": "2025-06-15T13:09:43.321104Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_dir = \"Dataset/DS7\"\n",
    "label_file = \"Dataset/ds7_labels.txt\"\n",
    "\n",
    "dataset = TEXBATSequenceDataset(\n",
    "    data_dir=data_dir,\n",
    "    label_file=label_file,\n",
    "    window_size=256,\n",
    "    pred_len=16,\n",
    "    step_size=32\n",
    ")\n",
    "\n",
    "# 尝试取一条看看\n",
    "x, y, label = dataset[0]\n",
    "print(\"x shape:\", x.shape)     # [256, 2]\n",
    "print(\"y shape:\", y.shape)     # [16, 2]\n",
    "print(\"label:\", label)         # tensor(0) or tensor(1)\n"
   ],
   "id": "4bbfafa8cc8501bf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: torch.Size([256, 2])\n",
      "y shape: torch.Size([16, 2])\n",
      "label: tensor(0)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T13:12:03.885541Z",
     "start_time": "2025-06-15T13:12:03.865771Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LSTMPredictor(nn.Module):\n",
    "    def __init__(self, input_dim=2, hidden_dim=64, num_layers=2, output_len=16):\n",
    "        super(LSTMPredictor, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_len = output_len\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_dim, hidden_size=hidden_dim,\n",
    "                            num_layers=num_layers, batch_first=True)\n",
    "\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 2)  # 预测复数（实部、虚部）\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [batch, seq_len=256, 2]\n",
    "        lstm_out, _ = self.lstm(x)  # 输出维度：[batch, seq_len, hidden]\n",
    "        last_outputs = lstm_out[:, -self.output_len:, :]  # 取最后 N 步\n",
    "        pred = self.linear(last_outputs)  # [batch, pred_len, 2]\n",
    "        return pred\n"
   ],
   "id": "ef255518d4b8d718",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T13:17:29.711413Z",
     "start_time": "2025-06-15T13:17:26.442248Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "model = LSTMPredictor().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ],
   "id": "2655126c262a087c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T13:17:49.639300Z",
     "start_time": "2025-06-15T13:17:49.632076Z"
    }
   },
   "cell_type": "code",
   "source": "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)",
   "id": "d25af1293571d96d",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T13:19:58.584904Z",
     "start_time": "2025-06-15T13:18:52.422457Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.train()\n",
    "for i, (x, y, label) in enumerate(train_loader):\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    output = model(x)\n",
    "    loss = criterion(output, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(f\"[Batch {i}] Loss: {loss.item():.6f}\")\n",
    "\n",
    "    if i == 30:  # 先跑 30 个 batch 看显存表现\n",
    "        break\n"
   ],
   "id": "76840bbe58804470",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 0] Loss: 2583088.500000\n",
      "[Batch 10] Loss: 2719219.000000\n",
      "[Batch 20] Loss: 2763033.250000\n",
      "[Batch 30] Loss: 2485623.000000\n"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "ATNrllFybOeY",
    "ExecuteTime": {
     "end_time": "2025-06-15T10:02:43.855653Z",
     "start_time": "2025-06-15T10:02:43.851434Z"
    }
   },
   "source": [
    "# 下载文件并命名为 Jamming_Classifier.zip\n",
    "# !wget -O Jamming_Classifier.zip \"https://zenodo.org/records/3783969/files/Jamming_Classifier.zip?download=1\"\n",
    "\n",
    "# 解压下载的 ZIP 文件\n",
    "# !unzip Jamming_Classifier.zip"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T10:02:49.350752Z",
     "start_time": "2025-06-15T10:02:43.943606Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 图像预处理：灰度图 → 256×256 → tensor (float32, 0~1)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),  # 强制灰度\n",
    "    transforms.Resize((256, 256)),                # 缩放到统一大小\n",
    "    transforms.ToTensor(),                        # 转换为 float32 & 归一化 [0,1]\n",
    "])\n",
    "\n",
    "# 设置路径（你原本是调反了，training 应该是训练集）\n",
    "train_dir = 'Dataset/Jamming_Classifier/Image_training_database'\n",
    "test_dir = 'Dataset/Jamming_Classifier/Image_testing_database'\n",
    "\n",
    "# 构建 PyTorch Dataset（仅记录路径 & 标签，不加载数据）\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root=test_dir, transform=transform)\n",
    "\n",
    "# 构建 DataLoader：每次只加载一小批，避免内存溢出\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "# 获取类别名（ImageFolder 会自动按文件夹排序生成类别标签）\n",
    "classes = train_dataset.classes\n",
    "print(\"类别标签顺序:\", classes)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "类别标签顺序: ['DME', 'NB', 'NoJam', 'SingleAM', 'SingleChirp', 'SingleFM']\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qKfbzvyS6Y5y",
    "outputId": "083c7493-33f6-4ea8-bf1c-e4e326fe890f",
    "ExecuteTime": {
     "end_time": "2025-06-15T10:02:49.545603Z",
     "start_time": "2025-06-15T10:02:49.378291Z"
    }
   },
   "source": [
    "import os\n",
    "# 统计每个类别的图像数量（保持与 ImageFolder 加载路径一致）\n",
    "def count_images(folder_path, classes, dataset_name):\n",
    "    print(f\"\\n{dataset_name} 圖片數量統計：\")\n",
    "    for label in classes:\n",
    "        label_dir = os.path.join(folder_path, label)\n",
    "        if not os.path.exists(label_dir):\n",
    "            print(f\"類別 {label} 不存在，跳過\")\n",
    "            continue\n",
    "        count = len([file for file in os.listdir(label_dir) if file.endswith('.bmp')])\n",
    "        print(f\"{label}: {count} 張\")\n",
    "\n",
    "# 使用之前定义的路径和类名\n",
    "count_images(train_dir, classes, '訓練集')\n",
    "count_images(test_dir, classes, '測試集')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "訓練集 圖片數量統計：\n",
      "DME: 10000 張\n",
      "NB: 10000 張\n",
      "NoJam: 10000 張\n",
      "SingleAM: 10000 張\n",
      "SingleChirp: 10000 張\n",
      "SingleFM: 10000 張\n",
      "\n",
      "測試集 圖片數量統計：\n",
      "DME: 10000 張\n",
      "NB: 10000 張\n",
      "NoJam: 10000 張\n",
      "SingleAM: 10000 張\n",
      "SingleChirp: 10000 張\n",
      "SingleFM: 10000 張\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T10:05:20.338239Z",
     "start_time": "2025-06-15T10:05:20.028221Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "# 使用预训练的 MobileNetV2 模型\n",
    "base_model = models.resnet34(weights=models.ResNet34_Weights.DEFAULT)\n",
    "\n",
    "# 修改第一层卷积层（将输入通道数从 3 改为 1）\n",
    "old_conv = base_model.conv1\n",
    "new_conv = nn.Conv2d(\n",
    "    in_channels=1,\n",
    "    out_channels=old_conv.out_channels,\n",
    "    kernel_size=old_conv.kernel_size,\n",
    "    stride=old_conv.stride,\n",
    "    padding=old_conv.padding,\n",
    "    bias=old_conv.bias is not None\n",
    ")\n",
    "\n",
    "# 平均 RGB 权重 → 适配灰度\n",
    "with torch.no_grad():\n",
    "    new_conv.weight = nn.Parameter(old_conv.weight.mean(dim=1, keepdim=True))\n",
    "\n",
    "base_model.conv1= new_conv\n",
    "\n",
    "# 获取类别数（来自 ImageFolder）\n",
    "num_classes = len(train_dataset.classes)\n",
    "\n",
    "# 替换分类头\n",
    "base_model.fc = nn.Linear(base_model.fc.in_features, num_classes)\n",
    "\n",
    "# 冻结特征层参数（可选）\n",
    "for param in base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in base_model.fc.parameters():\n",
    "    param.requires_grad=True\n",
    "\n",
    "# 显示模型结构确认\n",
    "print(base_model)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=6, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T10:07:02.749433Z",
     "start_time": "2025-06-15T10:07:00.931838Z"
    }
   },
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 损失函数：适用于多分类任务\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 只优化需要梯度更新的参数（即 requires_grad=True 的部分）\n",
    "trainable_params = filter(lambda p: p.requires_grad, base_model.parameters())\n",
    "\n",
    "# 优化器：只优化分类层\n",
    "optimizer = optim.Adam(trainable_params, lr=0.001)\n",
    "\n",
    "# 设置设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "base_model.to(device)\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mo8qY57s6fQm",
    "outputId": "9d3175d2-c84c-4796-af9e-c094bf32c966",
    "ExecuteTime": {
     "end_time": "2025-06-15T10:07:07.691303Z",
     "start_time": "2025-06-15T10:07:07.482734Z"
    }
   },
   "source": [
    "from torch.utils.data import random_split, DataLoader\n",
    "from torchvision import datasets\n",
    "\n",
    "# 原始 ImageFolder 的完整训练集\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "\n",
    "# 计算 80/20 分割\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_subset, val_subset = random_split(\n",
    "    train_dataset,\n",
    "    [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "# 构建 DataLoader（分批加载）\n",
    "train_loader = DataLoader(train_subset, batch_size=32, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_subset, batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "# 测试集 DataLoader（不变）\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "# 类别标签（来自 ImageFolder 自动识别的 class 文件夹名）\n",
    "classes = train_dataset.classes\n",
    "print(\"类别顺序:\", classes)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "类别顺序: ['DME', 'NB', 'NoJam', 'SingleAM', 'SingleChirp', 'SingleFM']\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "do6wouPQ7D55",
    "ExecuteTime": {
     "end_time": "2025-06-15T11:28:32.838683Z",
     "start_time": "2025-06-15T10:07:11.329066Z"
    }
   },
   "source": [
    "epochs = 30\n",
    "patience = 5\n",
    "best_val_loss = float('inf')\n",
    "best_state_dict = None\n",
    "epochs_no_improve = 0\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    base_model.train()  # 切换模型到训练模式\n",
    "    train_loss_sum = 0.0\n",
    "    train_correct = 0\n",
    "    total_train = 0\n",
    "\n",
    "    # 训练批次循环\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        # 将数据加载到计算设备\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        # 前向传播\n",
    "        # X_batch = X_batch.repeat(1, 3, 1, 1)  # 从灰度 (B,1,256,256) → RGB (B,3,256,256)\n",
    "        outputs = base_model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # 统计训练损失和准确度\n",
    "        train_loss_sum += loss.item() * y_batch.size(0)\n",
    "        _, pred_labels = torch.max(outputs, 1)\n",
    "        train_correct += (pred_labels == y_batch).sum().item()\n",
    "        total_train += y_batch.size(0)\n",
    "    # 计算平均训练损失和准确率\n",
    "    avg_train_loss = train_loss_sum / total_train\n",
    "    train_accuracy = train_correct / total_train\n",
    "\n",
    "    # 验证阶段\n",
    "    base_model.eval()  # 切换模型到评估模式\n",
    "    val_loss_sum = 0.0\n",
    "    val_correct = 0\n",
    "    total_val = 0\n",
    "    # 在验证集上不需要计算梯度\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            outputs = base_model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            # 累计验证损失和准确度\n",
    "            val_loss_sum += loss.item() * y_batch.size(0)\n",
    "            _, pred_labels = torch.max(outputs, 1)\n",
    "            val_correct += (pred_labels == y_batch).sum().item()\n",
    "            total_val += y_batch.size(0)\n",
    "    avg_val_loss = val_loss_sum / total_val\n",
    "    val_accuracy = val_correct / total_val\n",
    "\n",
    "    # 输出本轮训练的结果\n",
    "    print(f\"Epoch {epoch}/{epochs} - \"\n",
    "          f\"loss: {avg_train_loss:.4f} - accuracy: {train_accuracy:.4f} - \"\n",
    "          f\"val_loss: {avg_val_loss:.4f} - val_accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    # Early Stopping 检查：若验证损失改善，则保存最佳模型权重\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        best_state_dict = base_model.state_dict()  # 保存当前最佳状态\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\"验证集 loss 多次没有改善，提前停止训练。\")\n",
    "            if best_state_dict is not None:\n",
    "                base_model.load_state_dict(best_state_dict)  # 恢复最佳模型权重\n",
    "            break"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 - loss: 0.2192 - accuracy: 0.9292 - val_loss: 0.1321 - val_accuracy: 0.9530\n",
      "Epoch 2/30 - loss: 0.1287 - accuracy: 0.9522 - val_loss: 0.1065 - val_accuracy: 0.9583\n",
      "Epoch 3/30 - loss: 0.1127 - accuracy: 0.9576 - val_loss: 0.0971 - val_accuracy: 0.9653\n",
      "Epoch 4/30 - loss: 0.1089 - accuracy: 0.9592 - val_loss: 0.0978 - val_accuracy: 0.9637\n",
      "Epoch 5/30 - loss: 0.1032 - accuracy: 0.9605 - val_loss: 0.0921 - val_accuracy: 0.9666\n",
      "Epoch 6/30 - loss: 0.0980 - accuracy: 0.9630 - val_loss: 0.0896 - val_accuracy: 0.9659\n",
      "Epoch 7/30 - loss: 0.0952 - accuracy: 0.9631 - val_loss: 0.0823 - val_accuracy: 0.9700\n",
      "Epoch 8/30 - loss: 0.0909 - accuracy: 0.9636 - val_loss: 0.0830 - val_accuracy: 0.9702\n",
      "Epoch 9/30 - loss: 0.0933 - accuracy: 0.9636 - val_loss: 0.1198 - val_accuracy: 0.9564\n",
      "Epoch 10/30 - loss: 0.0909 - accuracy: 0.9648 - val_loss: 0.0775 - val_accuracy: 0.9710\n",
      "Epoch 11/30 - loss: 0.0875 - accuracy: 0.9659 - val_loss: 0.0769 - val_accuracy: 0.9713\n",
      "Epoch 12/30 - loss: 0.0876 - accuracy: 0.9665 - val_loss: 0.0872 - val_accuracy: 0.9690\n",
      "Epoch 13/30 - loss: 0.0873 - accuracy: 0.9666 - val_loss: 0.0925 - val_accuracy: 0.9670\n",
      "Epoch 14/30 - loss: 0.0849 - accuracy: 0.9670 - val_loss: 0.0768 - val_accuracy: 0.9721\n",
      "Epoch 15/30 - loss: 0.0840 - accuracy: 0.9677 - val_loss: 0.0754 - val_accuracy: 0.9716\n",
      "Epoch 16/30 - loss: 0.0848 - accuracy: 0.9677 - val_loss: 0.0758 - val_accuracy: 0.9722\n",
      "Epoch 17/30 - loss: 0.0836 - accuracy: 0.9675 - val_loss: 0.0777 - val_accuracy: 0.9723\n",
      "Epoch 18/30 - loss: 0.0850 - accuracy: 0.9678 - val_loss: 0.0756 - val_accuracy: 0.9719\n",
      "Epoch 19/30 - loss: 0.0829 - accuracy: 0.9678 - val_loss: 0.0819 - val_accuracy: 0.9703\n",
      "Epoch 20/30 - loss: 0.0838 - accuracy: 0.9665 - val_loss: 0.0785 - val_accuracy: 0.9694\n",
      "验证集 loss 多次没有改善，提前停止训练。\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T12:42:37.581039Z",
     "start_time": "2025-06-15T12:38:53.959158Z"
    }
   },
   "source": [
    "base_model.eval()  # 模型设为评估模式\n",
    "test_correct = 0\n",
    "total_test = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        # X_batch = X_batch.repeat(1, 3, 1, 1)  # 转换为 RGB 三通道\n",
    "        outputs = base_model(X_batch)\n",
    "        _, pred_labels = torch.max(outputs, 1)\n",
    "        test_correct += (pred_labels == y_batch).sum().item()\n",
    "        total_test += y_batch.size(0)\n",
    "\n",
    "test_accuracy = test_correct / total_test\n",
    "print(f\"测试集上的准确率: {test_accuracy * 100:.2f}%\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集上的准确率: 85.19%\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# 模型评估\n",
    "base_model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        outputs = base_model(X_batch)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(y_batch.cpu().numpy())\n",
    "\n",
    "# 计算评价指标\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(all_labels, all_preds, target_names=classes))\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(all_labels, all_preds))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "classifier",
   "language": "python",
   "name": "signal-classifier"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
